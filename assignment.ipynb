{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d44f214",
   "metadata": {},
   "source": [
    "# Programming for Data Analysis Assigment\n",
    "\n",
    "## Initial file creation, assignment to be specified at a later date\n",
    "\n",
    "\"For this project you must create a dataset by simulating a real-world phenomenon of your chooising. You may pick any phenomenon you wish - you might pick on that is of interest to you in your personal or professional life. Then, rather than collect data related to the phenomenon, you should model and synthesise such data using Python. We suggest you use the `numpy.random` package for this purpose.\n",
    "\n",
    "Specificailly, in this project you should:\n",
    "\n",
    "1. Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables;\n",
    "\n",
    "2. Investigate the types of variables involved, their likely distributions, and their relationships with each other;\n",
    "\n",
    "3. Synthesise/simulate a dataset as closely matching their properties as possible;\n",
    "\n",
    "4. Detail your research and implement the simulation in a Jupyter notebook - the dataset itself can simply be display in an output cell within the notebook.\n",
    "\n",
    "Note that this project is about simulation - you must synthesise a dataset. Some students may already have some real-world datasets in their own files. It is okay to base your synthesised dataset on these should you wish (please reference it if you do), but the main task is in this project is to create a synthesised dataset.\"\n",
    "\n",
    "For point two, it is not enough that you end up with a totally random dataset, you need to see which distribution might be most appropriate for that particular item. What are the likely data points that you collect from a phenomenon? How are the variables related to each other? What does the distribution look like? Is it a normal distribution? A Poisson distribution?\n",
    "\n",
    "It is sufficient for the dataset to be a pandas dataframe, it doesn't need to be a CSV or XML file.\n",
    "\n",
    "Brian: \"So I'm not actually that interested in the actual data. What we're most interested in is the research investigations you do to create the dataset, because presumably there will be some random element in the generation of your data, following some sort of distribution. And I'll be able to re-run your notebook and get a different randomly-generated dataset with the same properties.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0bc8fb",
   "metadata": {},
   "source": [
    "## Basic Plan\n",
    "\n",
    "So you need to find a basic dataset that can be extrapolated, rather than something comprehensive. The starting points should probably be either Hitting Against the Spin or the Vollman hockey book. This could be something team-based or player-based, something that can be condensed into small enough chunks that it fits into a 100 row by 5 column (for the four variables) grid.\n",
    "\n",
    "Remember that Brian's example was that he thinks there's a correlation between a student's grade and their level of degree, the amount of time spent studying and the number of commits they make.\n",
    "\n",
    "Could even be the amount of wins gained from winning the toss? Variables would be: toss result, choice of batting/fielding first, match result, total runs in the match. \n",
    "\n",
    "Vollman definitely tell you where he sources all of his data from, and I'm guessing it will be either NHL.com or hockey-reference.com. HAIS the spin should just be a matter of going to Cricinfo and seeing what we can dig out from their core metrics.\n",
    "\n",
    "After this you'll need to show investigation of each variable, and plot them accordingly using NumPy or Seaborn to see if a distribution can be identified. Once these are identified, even just using [Wikipedia](https://en.wikipedia.org/wiki/Probability_distribution#External_links) or the [NumPy documentation](https://numpy.org/doc/stable/reference/random/generator.html), you'll need to use the latest notebooks from this module to simulate a dataset accordingly, so if you plot, say, expected goals, and you can see that the data is Poisson-distributed, you can use the `poisson` function in NumPy to generate the data.\n",
    "\n",
    "\n",
    "Law: https://www.lords.org/mcc/the-laws-of-cricket/covering-the-pitch\n",
    "\n",
    "History: https://www.espncricinfo.com/story/cricket-s-turning-points-covered-pitches-461172\n",
    "\n",
    "History: https://www.espncricinfo.com/wisdenalmanack/content/story/152416.html\n",
    "\n",
    "Leamon, N. and Jones, B. (2021) Hitting Against the Spin: How Cricket Really Works. London: Little, Brown Book Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359055b",
   "metadata": {},
   "source": [
    "## Rationale\n",
    "\n",
    "Results in cricket matches between England and Australia since 1970, dependence on key variables:\n",
    "- where is the match played?\n",
    "- which team wins the toss?\n",
    "- did that team decide to bat or field?\n",
    "- what was the total first innings score?\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset, taken from CricInfo's [Statsguru](https://stats.espncricinfo.com/ci/engine/stats/index.html?class=1;filter=advanced;host=1;host=2;opposition=1;opposition=2;orderby=start;size=200;spanmin1=1+Jan+1970;spanval1=span;team=1;team=2;template=results;tournament_type=2;type=team;view=innings) query engine, details the match outcome of 153 five-day Test matches played between England and Australia in England, Wales and Australia since the 1st January, 1970. All but a handful of these matches were contested as part of the Ashes series, a series that alternates between the two countries approximately every two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b40659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# did you use all of these libraries?\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c21f6",
   "metadata": {},
   "source": [
    "Data: show a sample of data and explain each column and it's dimensions and possibilities, only first innings (quote from HATS about average scoring rates per innings. Any declared scores have been changed to a simple innings total to preserve the numeric dimension of the data, and the declaration listed as a seperate variable. For the sake of cleanliness, games hosted in Cardiff are list England as the host.\n",
    "\n",
    "Australian tosses: https://stats.espncricinfo.com/ci/engine/stats/index.html?class=1;filter=advanced;host=1;host=2;opposition=1;orderby=start;size=200;spanmin1=1+Jan+1970;spanval1=span;team=2;template=results;toss=1;tournament_type=2;type=team;view=innings\n",
    "\n",
    "English tosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff14d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee11ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
